{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:02.398974Z",
     "iopub.status.busy": "2022-11-21T20:11:02.398641Z",
     "iopub.status.idle": "2022-11-21T20:11:10.396528Z",
     "shell.execute_reply": "2022-11-21T20:11:10.395215Z",
     "shell.execute_reply.started": "2022-11-21T20:11:02.398920Z"
    },
    "id": "7rZnJaGTWQw0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Tensorflow Version: 2.5.0\n",
      "Pandas Version: 1.3.5\n",
      "Numpy Version: 1.19.5\n",
      "System Version: 3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:41:07) \n",
      "[Clang 11.1.0 ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"System Version: {sys.version}\")\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (17, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "notebookstart= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:10.401018Z",
     "iopub.status.busy": "2022-11-21T20:11:10.400414Z",
     "iopub.status.idle": "2022-11-21T20:11:10.409228Z",
     "shell.execute_reply": "2022-11-21T20:11:10.408189Z",
     "shell.execute_reply.started": "2022-11-21T20:11:10.400956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Loader Parameters\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "TRAIN_SPLIT = 300000\n",
    "\n",
    "# LSTM Parameters\n",
    "EVALUATION_INTERVAL = 200\n",
    "EPOCHS = 4\n",
    "PATIENCE = 5\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 13\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:10.413090Z",
     "iopub.status.busy": "2022-11-21T20:11:10.411272Z",
     "iopub.status.idle": "2022-11-21T20:11:15.159965Z",
     "shell.execute_reply": "2022-11-21T20:11:15.158994Z",
     "shell.execute_reply.started": "2022-11-21T20:11:10.411872Z"
    },
    "id": "xyv_i85IWInT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Shape: 300300 rows, 69 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>npart</th>\n",
       "      <th>tres</th>\n",
       "      <th>T</th>\n",
       "      <th>Z</th>\n",
       "      <th>N2a</th>\n",
       "      <th>OH</th>\n",
       "      <th>H2a</th>\n",
       "      <th>H</th>\n",
       "      <th>H2Oa</th>\n",
       "      <th>...</th>\n",
       "      <th>CO2b</th>\n",
       "      <th>C57O</th>\n",
       "      <th>C34</th>\n",
       "      <th>COb</th>\n",
       "      <th>R1</th>\n",
       "      <th>CH4b</th>\n",
       "      <th>RO</th>\n",
       "      <th>BV3</th>\n",
       "      <th>H2Ob</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.163410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.038780</td>\n",
       "      <td>0.265810</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.684630e-11</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.873640e-11</td>\n",
       "      <td>0.158957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.256400e-11</td>\n",
       "      <td>0.163735</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.263476</td>\n",
       "      <td>0.158957</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.630020e-11</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.898560e-11</td>\n",
       "      <td>0.159205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.716870e-10</td>\n",
       "      <td>0.164052</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.038876</td>\n",
       "      <td>0.261218</td>\n",
       "      <td>0.159205</td>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.582240e-11</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.919680e-11</td>\n",
       "      <td>0.159446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.465540e-10</td>\n",
       "      <td>0.164362</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.038920</td>\n",
       "      <td>0.259033</td>\n",
       "      <td>0.159446</td>\n",
       "      <td>0.003415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.540330e-11</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.938010e-11</td>\n",
       "      <td>0.159679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.196690e-09</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.038963</td>\n",
       "      <td>0.256919</td>\n",
       "      <td>0.159679</td>\n",
       "      <td>0.004480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  npart  tres       T    Z  N2a            OH       H2a  \\\n",
       "0           0    1.0   0.0  1073.0  0.0  0.0  0.000000e+00  0.000000   \n",
       "1           1    1.0   0.0  1073.0  0.0  0.0  1.684630e-11  0.000003   \n",
       "2           2    1.0   0.0  1073.0  0.0  0.0  1.630020e-11  0.000006   \n",
       "3           3    1.0   0.0  1073.0  0.0  0.0  1.582240e-11  0.000008   \n",
       "4           4    1.0   0.0  1073.0  0.0  0.0  1.540330e-11  0.000011   \n",
       "\n",
       "              H      H2Oa  ...      CO2b  C57O           C34       COb  \\\n",
       "0  0.000000e+00  0.158700  ...  0.062780   0.0  0.000000e+00  0.163410   \n",
       "1  1.873640e-11  0.158957  ...  0.062882   0.0  6.256400e-11  0.163735   \n",
       "2  1.898560e-11  0.159205  ...  0.062980   0.0  2.716870e-10  0.164052   \n",
       "3  1.919680e-11  0.159446  ...  0.063075   0.0  6.465540e-10  0.164362   \n",
       "4  1.938010e-11  0.159679  ...  0.063167   0.0  1.196690e-09  0.164665   \n",
       "\n",
       "         R1      CH4b        RO       BV3      H2Ob        R2  \n",
       "0  0.000000  0.009350  0.038780  0.265810  0.158700  0.000000  \n",
       "1  0.000011  0.009375  0.038829  0.263476  0.158957  0.001176  \n",
       "2  0.000022  0.009400  0.038876  0.261218  0.159205  0.002314  \n",
       "3  0.000033  0.009425  0.038920  0.259033  0.159446  0.003415  \n",
       "4  0.000044  0.009449  0.038963  0.256919  0.159679  0.004480  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data.csv')\n",
    "print(\"DataFrame Shape: {} rows, {} columns\".format(*df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlJYi3_HXcw8"
   },
   "source": [
    "## Part 2: Forecast a multivariate time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoxNZ2GM7DPm"
   },
   "source": [
    "The original dataset contains fourteen features. For simplicity, this section considers only three of the original fourteen. The features used are air temperature, atmospheric pressure, and air density. \n",
    "\n",
    "To use more features, add their names to this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:23.876765Z",
     "iopub.status.busy": "2022-11-21T20:11:23.876342Z",
     "iopub.status.idle": "2022-11-21T20:11:23.885140Z",
     "shell.execute_reply": "2022-11-21T20:11:23.883943Z",
     "shell.execute_reply.started": "2022-11-21T20:11:23.876706Z"
    },
    "id": "DphrB7bxSNDd"
   },
   "outputs": [],
   "source": [
    "features_considered = ['npart',\n",
    " 'tres',\n",
    " 'T',\n",
    " 'Z',\n",
    " 'N2a',\n",
    " 'OH',\n",
    " 'H2a',\n",
    " 'H',\n",
    " 'H2Oa',\n",
    " 'COa',\n",
    " 'CO2a',\n",
    " 'HCO',\n",
    " 'CH2O',\n",
    " 'CH2OH',\n",
    " 'CH3',\n",
    " 'CH4a',\n",
    " 'C2H5',\n",
    " 'CH3OH',\n",
    " 'C2H2',\n",
    " 'C2H3',\n",
    " 'CH2CO',\n",
    " 'CH2CHO',\n",
    " 'CH3CHO',\n",
    " 'C2H4',\n",
    " 'C2H6',\n",
    " 'CH3COCH3',\n",
    " 'C3H3',\n",
    " 'A1-C6H6',\n",
    " 'C5H6',\n",
    " 'C5H5',\n",
    " 'C9H8',\n",
    " 'C9H7',\n",
    " 'A1CH2-C7H7',\n",
    " 'A2-C10H8',\n",
    " 'A1OH-C6H6O',\n",
    " 'LVG-C6H10O5',\n",
    " 'HMFU-C6H6O3',\n",
    " 'C3H4O3',\n",
    " 'C5H4O2',\n",
    " 'C2H2O2',\n",
    " 'HAA-C2H4O2',\n",
    " 'XYLOSE-C5H8O',\n",
    " 'C11H12O4',\n",
    " 'C8H10O3',\n",
    " 'COUMARYL-C9H',\n",
    " 'C2H5OH',\n",
    " 'HCOOH',\n",
    " 'CH3O',\n",
    " 'BV2',\n",
    " 'N2b',\n",
    " 'C2',\n",
    " 'C57',\n",
    " 'C34O',\n",
    " 'C1',\n",
    " 'RAD',\n",
    " 'BV1',\n",
    " 'H2b',\n",
    " 'C2O',\n",
    " 'CO2b',\n",
    " 'C57O',\n",
    " 'C34',\n",
    " 'COb',\n",
    " 'R1',\n",
    " 'CH4b',\n",
    " 'RO',\n",
    " 'BV3',\n",
    " 'H2Ob',\n",
    " 'R2']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:24.311741Z",
     "iopub.status.busy": "2022-11-21T20:11:24.311363Z",
     "iopub.status.idle": "2022-11-21T20:11:24.396009Z",
     "shell.execute_reply": "2022-11-21T20:11:24.394706Z",
     "shell.execute_reply.started": "2022-11-21T20:11:24.311684Z"
    },
    "id": "IfQUSiJfUpXJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npart</th>\n",
       "      <th>tres</th>\n",
       "      <th>T</th>\n",
       "      <th>Z</th>\n",
       "      <th>N2a</th>\n",
       "      <th>OH</th>\n",
       "      <th>H2a</th>\n",
       "      <th>H</th>\n",
       "      <th>H2Oa</th>\n",
       "      <th>COa</th>\n",
       "      <th>...</th>\n",
       "      <th>CO2b</th>\n",
       "      <th>C57O</th>\n",
       "      <th>C34</th>\n",
       "      <th>COb</th>\n",
       "      <th>R1</th>\n",
       "      <th>CH4b</th>\n",
       "      <th>RO</th>\n",
       "      <th>BV3</th>\n",
       "      <th>H2Ob</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.163410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.163410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.038780</td>\n",
       "      <td>0.265810</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.684630e-11</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.873640e-11</td>\n",
       "      <td>0.158957</td>\n",
       "      <td>0.163735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.256400e-11</td>\n",
       "      <td>0.163735</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.263476</td>\n",
       "      <td>0.158957</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.630020e-11</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.898560e-11</td>\n",
       "      <td>0.159205</td>\n",
       "      <td>0.164052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.716870e-10</td>\n",
       "      <td>0.164052</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.038876</td>\n",
       "      <td>0.261218</td>\n",
       "      <td>0.159205</td>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.582240e-11</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.919680e-11</td>\n",
       "      <td>0.159446</td>\n",
       "      <td>0.164362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.465540e-10</td>\n",
       "      <td>0.164362</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.038920</td>\n",
       "      <td>0.259033</td>\n",
       "      <td>0.159446</td>\n",
       "      <td>0.003415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.540330e-11</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.938010e-11</td>\n",
       "      <td>0.159679</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.196690e-09</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.038963</td>\n",
       "      <td>0.256919</td>\n",
       "      <td>0.159679</td>\n",
       "      <td>0.004480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            npart  tres       T    Z  N2a            OH       H2a  \\\n",
       "Unnamed: 0                                                          \n",
       "0             1.0   0.0  1073.0  0.0  0.0  0.000000e+00  0.000000   \n",
       "1             1.0   0.0  1073.0  0.0  0.0  1.684630e-11  0.000003   \n",
       "2             1.0   0.0  1073.0  0.0  0.0  1.630020e-11  0.000006   \n",
       "3             1.0   0.0  1073.0  0.0  0.0  1.582240e-11  0.000008   \n",
       "4             1.0   0.0  1073.0  0.0  0.0  1.540330e-11  0.000011   \n",
       "\n",
       "                       H      H2Oa       COa  ...      CO2b  C57O  \\\n",
       "Unnamed: 0                                    ...                   \n",
       "0           0.000000e+00  0.158700  0.163410  ...  0.062780   0.0   \n",
       "1           1.873640e-11  0.158957  0.163735  ...  0.062882   0.0   \n",
       "2           1.898560e-11  0.159205  0.164052  ...  0.062980   0.0   \n",
       "3           1.919680e-11  0.159446  0.164362  ...  0.063075   0.0   \n",
       "4           1.938010e-11  0.159679  0.164665  ...  0.063167   0.0   \n",
       "\n",
       "                     C34       COb        R1      CH4b        RO       BV3  \\\n",
       "Unnamed: 0                                                                   \n",
       "0           0.000000e+00  0.163410  0.000000  0.009350  0.038780  0.265810   \n",
       "1           6.256400e-11  0.163735  0.000011  0.009375  0.038829  0.263476   \n",
       "2           2.716870e-10  0.164052  0.000022  0.009400  0.038876  0.261218   \n",
       "3           6.465540e-10  0.164362  0.000033  0.009425  0.038920  0.259033   \n",
       "4           1.196690e-09  0.164665  0.000044  0.009449  0.038963  0.256919   \n",
       "\n",
       "                H2Ob        R2  \n",
       "Unnamed: 0                      \n",
       "0           0.158700  0.000000  \n",
       "1           0.158957  0.001176  \n",
       "2           0.159205  0.002314  \n",
       "3           0.159446  0.003415  \n",
       "4           0.159679  0.004480  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df[features_considered]\n",
    "features.index = df['Unnamed: 0']\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSfhTZi5r15R"
   },
   "source": [
    "Let's have a look at how each of these features vary across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:25.722693Z",
     "iopub.status.busy": "2022-11-21T20:11:25.722264Z",
     "iopub.status.idle": "2022-11-21T20:11:25.729399Z",
     "shell.execute_reply": "2022-11-21T20:11:25.728135Z",
     "shell.execute_reply.started": "2022-11-21T20:11:25.722634Z"
    },
    "id": "QdgC8zvGr21X"
   },
   "outputs": [],
   "source": [
    "#features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:25.892127Z",
     "iopub.status.busy": "2022-11-21T20:11:25.891790Z",
     "iopub.status.idle": "2022-11-21T20:11:25.906249Z",
     "shell.execute_reply": "2022-11-21T20:11:25.905196Z",
     "shell.execute_reply.started": "2022-11-21T20:11:25.892075Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:26.472296Z",
     "iopub.status.busy": "2022-11-21T20:11:26.471862Z",
     "iopub.status.idle": "2022-11-21T20:11:28.624269Z",
     "shell.execute_reply": "2022-11-21T20:11:28.623198Z",
     "shell.execute_reply.started": "2022-11-21T20:11:26.472225Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/644649297gd0_6hzy4hf6yl00000gn/T/ipykernel_44473/4134530531.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 41.24 MB\n",
      "Decreased by 73.9%\n"
     ]
    }
   ],
   "source": [
    "features = reduce_mem_usage(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqStgZ-O1b3_"
   },
   "source": [
    "As mentioned, the first step will be to standardize the dataset using the mean and standard deviation of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:31.179424Z",
     "iopub.status.busy": "2022-11-21T20:11:31.178980Z",
     "iopub.status.idle": "2022-11-21T20:11:33.078696Z",
     "shell.execute_reply": "2022-11-21T20:11:33.077583Z",
     "shell.execute_reply.started": "2022-11-21T20:11:31.179359Z"
    },
    "id": "W7VuNIwfHRHx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
      "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "dataset = features.values\n",
    "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
    "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:33.193670Z",
     "iopub.status.busy": "2022-11-21T20:11:33.193303Z",
     "iopub.status.idle": "2022-11-21T20:11:33.226220Z",
     "shell.execute_reply": "2022-11-21T20:11:33.225275Z",
     "shell.execute_reply.started": "2022-11-21T20:11:33.193612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npart</th>\n",
       "      <th>tres</th>\n",
       "      <th>T</th>\n",
       "      <th>Z</th>\n",
       "      <th>N2a</th>\n",
       "      <th>OH</th>\n",
       "      <th>H2a</th>\n",
       "      <th>H</th>\n",
       "      <th>H2Oa</th>\n",
       "      <th>COa</th>\n",
       "      <th>...</th>\n",
       "      <th>CO2b</th>\n",
       "      <th>C57O</th>\n",
       "      <th>C34</th>\n",
       "      <th>COb</th>\n",
       "      <th>R1</th>\n",
       "      <th>CH4b</th>\n",
       "      <th>RO</th>\n",
       "      <th>BV3</th>\n",
       "      <th>H2Ob</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.163452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>0.038788</td>\n",
       "      <td>0.265869</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158936</td>\n",
       "      <td>0.163696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163696</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.038818</td>\n",
       "      <td>0.263428</td>\n",
       "      <td>0.158936</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>0.261230</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159424</td>\n",
       "      <td>0.164307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164307</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.038910</td>\n",
       "      <td>0.259033</td>\n",
       "      <td>0.159424</td>\n",
       "      <td>0.003414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159668</td>\n",
       "      <td>0.164673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164673</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>0.038971</td>\n",
       "      <td>0.256836</td>\n",
       "      <td>0.159668</td>\n",
       "      <td>0.004478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            npart  tres       T    Z  N2a   OH       H2a    H      H2Oa  \\\n",
       "Unnamed: 0                                                                \n",
       "0             1.0   0.0  1073.0  0.0  0.0  0.0  0.000000  0.0  0.158691   \n",
       "1             1.0   0.0  1073.0  0.0  0.0  0.0  0.000003  0.0  0.158936   \n",
       "2             1.0   0.0  1073.0  0.0  0.0  0.0  0.000006  0.0  0.159180   \n",
       "3             1.0   0.0  1073.0  0.0  0.0  0.0  0.000008  0.0  0.159424   \n",
       "4             1.0   0.0  1073.0  0.0  0.0  0.0  0.000011  0.0  0.159668   \n",
       "\n",
       "                 COa  ...      CO2b  C57O  C34       COb        R1      CH4b  \\\n",
       "Unnamed: 0            ...                                                      \n",
       "0           0.163452  ...  0.062805   0.0  0.0  0.163452  0.000000  0.009354   \n",
       "1           0.163696  ...  0.062866   0.0  0.0  0.163696  0.000011  0.009377   \n",
       "2           0.164062  ...  0.062988   0.0  0.0  0.164062  0.000022  0.009399   \n",
       "3           0.164307  ...  0.063049   0.0  0.0  0.164307  0.000033  0.009422   \n",
       "4           0.164673  ...  0.063171   0.0  0.0  0.164673  0.000044  0.009453   \n",
       "\n",
       "                  RO       BV3      H2Ob        R2  \n",
       "Unnamed: 0                                          \n",
       "0           0.038788  0.265869  0.158691  0.000000  \n",
       "1           0.038818  0.263428  0.158936  0.001176  \n",
       "2           0.038879  0.261230  0.159180  0.002314  \n",
       "3           0.038910  0.259033  0.159424  0.003414  \n",
       "4           0.038971  0.256836  0.159668  0.004478  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(dataset, columns = features.columns, index= features.index).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyuGuJUgjUK3"
   },
   "source": [
    "### Single step model\n",
    "In a single step setup, the model learns to predict a single point in the future based on some history provided.\n",
    "\n",
    "The below function performs the same windowing task as below, however, here it samples the past observation based on the step size given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:35.095681Z",
     "iopub.status.busy": "2022-11-21T20:11:35.095255Z",
     "iopub.status.idle": "2022-11-21T20:11:35.103836Z",
     "shell.execute_reply": "2022-11-21T20:11:35.102335Z",
     "shell.execute_reply.started": "2022-11-21T20:11:35.095622Z"
    },
    "id": "d-rVX4d3OF86"
   },
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        if single_step:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWVGYwbN2ITI"
   },
   "source": [
    "In this tutorial, the network is shown data from the last five (5) days, i.e. 720 observations that are sampled every hour. The sampling is done every one hour since a drastic change is not expected within 60 minutes. Thus, 120 observation represent history of the last five days.  For the single step prediction model, the label for a datapoint is the temperature 12 hours into the future. In order to create a label for this, the temperature after 72(12*6) observations is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:36.368693Z",
     "iopub.status.busy": "2022-11-21T20:11:36.368279Z",
     "iopub.status.idle": "2022-11-21T20:11:50.435542Z",
     "shell.execute_reply": "2022-11-21T20:11:50.434417Z",
     "shell.execute_reply.started": "2022-11-21T20:11:36.368639Z"
    },
    "id": "HlhVGzPhmMYI"
   },
   "outputs": [],
   "source": [
    "past_history = 720\n",
    "future_target = 72\n",
    "STEP = 6\n",
    "\n",
    "x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 1], 0,\n",
    "                                                   TRAIN_SPLIT, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:53.825336Z",
     "iopub.status.busy": "2022-11-21T20:11:53.824878Z",
     "iopub.status.idle": "2022-11-21T20:11:53.830741Z",
     "shell.execute_reply": "2022-11-21T20:11:53.829341Z",
     "shell.execute_reply.started": "2022-11-21T20:11:53.825274Z"
    }
   },
   "outputs": [],
   "source": [
    "x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 1],\n",
    "                                               TRAIN_SPLIT, None, past_history,\n",
    "                                               future_target, STEP,\n",
    "                                               single_step=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CamMObrwPhnp"
   },
   "source": [
    "Let's look at a single data-point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:11:58.389584Z",
     "iopub.status.busy": "2022-11-21T20:11:58.389182Z",
     "iopub.status.idle": "2022-11-21T20:11:58.395904Z",
     "shell.execute_reply": "2022-11-21T20:11:58.394950Z",
     "shell.execute_reply.started": "2022-11-21T20:11:58.389526Z"
    },
    "id": "_tVKm-ZIPls0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299280, 120, 68)\n",
      "Single window of past history : (120, 68)\n",
      "(120, 68)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_single.shape)\n",
    "print ('Single window of past history : {}'.format(x_train_single[0].shape))\n",
    "print(x_train_single.shape[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T20:12:04.504064Z",
     "iopub.status.busy": "2022-11-21T20:12:04.503657Z"
    },
    "id": "eCWG4xgQ3O6E"
   },
   "outputs": [],
   "source": [
    "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\n",
    "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\n",
    "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aWec9_nlxBl"
   },
   "outputs": [],
   "source": [
    "single_step_model = tf.keras.models.Sequential()\n",
    "single_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                           input_shape=x_train_single.shape[-2:]))\n",
    "single_step_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYhUfWjwOPFN"
   },
   "source": [
    "Let's check out a sample prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yY7FodHVOPsH"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_single.take(1):\n",
    "    print(single_step_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0jnt2l2mwkl"
   },
   "outputs": [],
   "source": [
    "print(f\"Evaluation Threshold: {EVALUATION_INTERVAL}\",\n",
    "      f\"Epochs: {EPOCHS}\", sep=\"\\n\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 3, restore_best_weights=True)\n",
    "single_step_history = single_step_model.fit(train_data_single,\n",
    "                                            epochs=EPOCHS,\n",
    "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                            validation_data=val_data_single,\n",
    "                                            callbacks=[early_stopping],\n",
    "                                            validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZAdeAnP5c72"
   },
   "outputs": [],
   "source": [
    "def plot_train_history(history, title):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(loss))\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8lBKA-z5yYV"
   },
   "outputs": [],
   "source": [
    "plot_train_history(single_step_history,\n",
    "                   'Single Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfjrGAlEUp7i"
   },
   "source": [
    "#### Predict a single step future\n",
    "Now that the model is trained, let's make a few sample predictions. The model is given the history of three features over the past five days sampled every hour (120 data-points), since the goal is to predict the temperature, the plot only displays the past temperature. The prediction is made one day into the future (hence the gap between the history and prediction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1qmPLLVUpuN"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_single.take(3):\n",
    "    plot = show_plot([x[0][:, 1].numpy(), y[0].numpy(),\n",
    "                    single_step_model.predict(x)[0]], 12,\n",
    "                   'Single Step Prediction')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del single_step_history, val_data_single, train_data_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GnE087bJYSu"
   },
   "source": [
    "### Multi-Step model\n",
    "In a multi-step prediction model, given a past history, the model needs to learn to predict a range of future values. Thus, unlike a single step model, where only a single future point is predicted, a multi-step model predict a sequence of the future.\n",
    "\n",
    "For the multi-step model, the training data again consists of recordings over the past five days sampled every hour. However, here, the model needs to learn to predict the temperature for the next 12 hours. Since an obversation is taken every 10 minutes, the output is 72 predictions. For this task, the dataset needs to be prepared accordingly, thus the first step is just to create it again, but with a different target window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZCk9fqyJZqX"
   },
   "outputs": [],
   "source": [
    "past_history = 720\n",
    "future_target = 72\n",
    "STEP = 6\n",
    "\n",
    "x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, 1], 0,\n",
    "                                                 TRAIN_SPLIT, past_history,\n",
    "                                                 future_target, STEP)\n",
    "x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, 1],\n",
    "                                             TRAIN_SPLIT, None, past_history,\n",
    "                                             future_target, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LImXPwAGRtWy"
   },
   "source": [
    "Let's check out a sample data-point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpWDcBkQRwS-"
   },
   "outputs": [],
   "source": [
    "print (x_train_multi.shape,\n",
    "       y_train_multi.shape,\n",
    "       'Single window of past history : {}'.format(x_train_multi[0].shape),\n",
    "       'Target temperature to predict : {}'.format(y_train_multi[0].shape),\n",
    "       sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjR4PJArMOpA"
   },
   "outputs": [],
   "source": [
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZcg8FWpSG8K"
   },
   "source": [
    "Plotting a sample data-point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksXKVbwBV7D3"
   },
   "outputs": [],
   "source": [
    "def multi_step_plot(history, true_future, prediction):\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "\n",
    "    plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
    "           label='True Future')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
    "                 label='Predicted Future')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCQKetflZRMF"
   },
   "source": [
    "In this plot and subsequent similar plots, the history and the future data are sampled every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6G8bacQR4w2"
   },
   "outputs": [],
   "source": [
    "for x, y in train_data_multi.take(1):\n",
    "    multi_step_plot(x[0], y[0], np.array([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOjz8DzZ4HFS"
   },
   "source": [
    "Since the task here is a bit more complicated than the previous task, the model now consists of two LSTM layers. Finally, since 72 predictions are made, the dense layer outputs 72 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byAl0NKSNBP6"
   },
   "outputs": [],
   "source": [
    "multi_step_model = tf.keras.models.Sequential()\n",
    "multi_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                          return_sequences=True,\n",
    "                                          input_shape=x_train_multi.shape[-2:]))\n",
    "multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
    "multi_step_model.add(tf.keras.layers.Dense(72))\n",
    "\n",
    "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\n",
    "print(multi_step_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvB7zBqVSMyl"
   },
   "source": [
    "Let's see how the model predicts before it trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13_ZWvB9SRlZ"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(1):\n",
    "    print (multi_step_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uwOhXo3Oems"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 3, restore_best_weights=True)\n",
    "multi_step_history = multi_step_model.fit(train_data_multi,\n",
    "                                          epochs=EPOCHS,\n",
    "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                          validation_data=val_data_multi,\n",
    "                                          validation_steps=EVALUATION_INTERVAL,\n",
    "                                          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKfQoBjQ5l7U"
   },
   "outputs": [],
   "source": [
    "plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDg94-yq4pas"
   },
   "source": [
    "#### Predict a multi-step future\n",
    "Let's now have a look at how well your network has learnt to predict the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dt22wq6fyIBU"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(3):\n",
    "    multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del multi_step_model, val_data_multi, train_data_multi\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "This tutorial was a quick introduction to time series forecasting using an RNN. You may now try to predict the stock market and become a billionaire.\n",
    "\n",
    "In addition, you may also write a generator to yield data (instead of the uni/multivariate_data function), which would be more memory efficient. You may also check out this [time series windowing](https://www.tensorflow.org/guide/data#time_series_windowing) guide and use it in this tutorial.\n",
    "\n",
    "For further understanding, you may read Chapter 15 of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/), 2nd Edition and Chapter 6 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Step, Multi-Input, and Multi-Output\n",
    "\n",
    "_By Nick Brooks, Feb 2020_\n",
    "\n",
    "Inspired by the following paper:\n",
    "\n",
    "- https://arxiv.org/abs/1903.02791\n",
    "- https://github.com/niklascp/bus-arrival-convlstm/tree/master/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T19:34:33.830235Z",
     "iopub.status.busy": "2022-11-21T19:34:33.829758Z",
     "iopub.status.idle": "2022-11-21T19:34:33.841396Z",
     "shell.execute_reply": "2022-11-21T19:34:33.840239Z",
     "shell.execute_reply.started": "2022-11-21T19:34:33.830175Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T19:34:47.569347Z",
     "iopub.status.busy": "2022-11-21T19:34:47.568941Z",
     "iopub.status.idle": "2022-11-21T19:34:47.582328Z",
     "shell.execute_reply": "2022-11-21T19:34:47.581070Z",
     "shell.execute_reply.started": "2022-11-21T19:34:47.569291Z"
    }
   },
   "outputs": [],
   "source": [
    "def multivariate_multioutput_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        if single_step:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data)[:,:,:,np.newaxis,np.newaxis], np.array(labels)[:,:,:,np.newaxis,np.newaxis]\n",
    "\n",
    "def multi_step_output_plot(history, true_future, prediction):\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "    \n",
    "    for i, (var, c) in enumerate(zip(features.columns[:2], ['b','r'])):\n",
    "        plt.plot(num_in, np.array(history[:, i]), c, label=var)\n",
    "        plt.plot(np.arange(num_out)/STEP, np.array(true_future[:,i]), c+'o', markersize=5, alpha=0.5,\n",
    "               label=f\"True {var.title()}\")\n",
    "        if prediction.any():\n",
    "            plt.plot(np.arange(num_out)/STEP, np.array(prediction[:,i]), '*', markersize=5, alpha=0.5,\n",
    "                     label=f\"Predicted {var.title()}\")\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_target = 72\n",
    "x_train_multi, y_train_multi = multivariate_multioutput_data(dataset[:,:2], dataset[:,:2], 0,\n",
    "                                                 TRAIN_SPLIT, past_history,\n",
    "                                                 future_target, STEP)\n",
    "x_val_multi, y_val_multi = multivariate_multioutput_data(dataset[:,:2], dataset[:, :2],\n",
    "                                             TRAIN_SPLIT, None, past_history,\n",
    "                                             future_target, STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x_train_multi.shape,\n",
    "       y_train_multi.shape,\n",
    "       x_val_multi.shape,\n",
    "       y_val_multi.shape,\n",
    "       'Single window of past history : {}'.format(x_train_multi[0].shape),\n",
    "       'Target temperature to predict : {}'.format(y_train_multi[0].shape),\n",
    "       sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(10):\n",
    "    multi_step_output_plot(np.squeeze(x[0]), np.squeeze(y[0]), np.array([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional LSTM\n",
    "\n",
    "As taken from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_timesteps, output_timesteps, num_links, num_inputs):\n",
    "    # COPY PASTA\n",
    "    # https://github.com/niklascp/bus-arrival-convlstm/blob/master/jupyter/ConvLSTM_3x15min_10x64-5x64-10x64-5x64-Comparison.ipynb\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, num_inputs, 1, 1)))\n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_1',\n",
    "                         filters = 64, kernel_size = (10, 1),                       \n",
    "                         padding = 'same', \n",
    "                         return_sequences = True))\n",
    "    \n",
    "    model.add(Dropout(0.30, name = 'dropout_1'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_1'))\n",
    "\n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_2',\n",
    "                         filters = 64, kernel_size = (5, 1), \n",
    "                         padding='same',\n",
    "                         return_sequences = False))\n",
    "    \n",
    "    model.add(Dropout(0.20, name = 'dropout_2'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_2'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(output_timesteps))\n",
    "    model.add(Reshape((output_timesteps, num_inputs, 1, 64)))\n",
    "    \n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_3',\n",
    "                         filters = 64, kernel_size = (10, 1), \n",
    "                         padding='same',\n",
    "                         return_sequences = True))\n",
    "    \n",
    "    model.add(Dropout(0.20, name = 'dropout_3'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_3'))\n",
    "    \n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_4',\n",
    "                         filters = 64, kernel_size = (5, 1), \n",
    "                         padding='same',\n",
    "                         return_sequences = True))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(units=1, name = 'dense_1', activation = 'relu')))\n",
    "    model.add(Dense(units=1, name = 'dense_2', activation = 'linear'))\n",
    "\n",
    "#     optimizer = RMSprop() #lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.9)\n",
    "#     optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "    optimizer = tf.keras.optimizers.RMSprop(lr=0.004, clipvalue=1.0)\n",
    "    model.compile(loss = \"mse\", optimizer = optimizer, metrics = ['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_target = 72\n",
    "x_train_multi, y_train_multi = multivariate_multioutput_data(dataset[:,:2], dataset[:,:2], 0,\n",
    "                                                 TRAIN_SPLIT, past_history,\n",
    "                                                 future_target, STEP)\n",
    "x_val_multi, y_val_multi = multivariate_multioutput_data(dataset[:,:2], dataset[:, :2],\n",
    "                                             TRAIN_SPLIT, None, past_history,\n",
    "                                             future_target, STEP)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "steps_per_epoch = 350\n",
    "validation_steps = 500\n",
    "\n",
    "modelstart = time.time()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = PATIENCE, restore_best_weights=True)\n",
    "model = build_model(x_train_multi.shape[1], future_target, y_train_multi.shape[2], x_train_multi.shape[2])\n",
    "print(model.summary())\n",
    "\n",
    "# Train\n",
    "print(\"\\nTRAIN MODEL...\")\n",
    "history = model.fit(train_data_multi,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data=val_data_multi,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stopping])\n",
    "model.save('multi-output-timesteps.h5')\n",
    "print(\"\\nModel Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_history(history, 'Multi-Step, Multi-Output Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(10):\n",
    "    multi_step_output_plot(np.squeeze(x[0]), np.squeeze(y[0]), np.squeeze(model.predict(x[0][np.newaxis,:,:,:,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified the Convolutional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_timesteps, output_timesteps, num_links, num_inputs):    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, num_inputs, 1, 1)))\n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_1',\n",
    "                         filters = 64, kernel_size = (10, 1),                       \n",
    "                         padding = 'same', \n",
    "                         return_sequences = False))\n",
    "    \n",
    "    model.add(Dropout(0.30, name = 'dropout_1'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_1'))\n",
    "\n",
    "#     model.add(ConvLSTM2D(name ='conv_lstm_2',\n",
    "#                          filters = 64, kernel_size = (5, 1), \n",
    "#                          padding='same',\n",
    "#                          return_sequences = False))\n",
    "    \n",
    "#     model.add(Dropout(0.20, name = 'dropout_2'))\n",
    "#     model.add(BatchNormalization(name = 'batch_norm_2'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(output_timesteps))\n",
    "    model.add(Reshape((output_timesteps, num_inputs, 1, 64)))\n",
    "    \n",
    "#     model.add(ConvLSTM2D(name ='conv_lstm_3',\n",
    "#                          filters = 64, kernel_size = (10, 1), \n",
    "#                          padding='same',\n",
    "#                          return_sequences = True))\n",
    "    \n",
    "#     model.add(Dropout(0.20, name = 'dropout_3'))\n",
    "#     model.add(BatchNormalization(name = 'batch_norm_3'))\n",
    "    \n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_4',\n",
    "                         filters = 64, kernel_size = (5, 1), \n",
    "                         padding='same',\n",
    "                         return_sequences = True))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(units=1, name = 'dense_1', activation = 'relu')))\n",
    "    model.add(Dense(units=1, name = 'dense_2'))\n",
    "\n",
    "#     optimizer = RMSprop() #lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.9)\n",
    "#     optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "    optimizer = tf.keras.optimizers.RMSprop(lr=0.003, clipvalue=1.0)\n",
    "    model.compile(loss = \"mse\", optimizer = optimizer, metrics = ['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend Prediction Window..\n",
    "future_target = 144\n",
    "x_train_multi, y_train_multi = multivariate_multioutput_data(dataset[:,:2], dataset[:,:2], 0,\n",
    "                                                 TRAIN_SPLIT, past_history,\n",
    "                                                 future_target, STEP)\n",
    "x_val_multi, y_val_multi = multivariate_multioutput_data(dataset[:,:2], dataset[:, :2],\n",
    "                                             TRAIN_SPLIT, None, past_history,\n",
    "                                             future_target, STEP)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "steps_per_epoch = 350\n",
    "validation_steps = 500\n",
    "\n",
    "modelstart = time.time()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = PATIENCE, restore_best_weights=True)\n",
    "model = build_model(x_train_multi.shape[1], future_target, y_train_multi.shape[2], x_train_multi.shape[2])\n",
    "print(model.summary())\n",
    "\n",
    "# Train\n",
    "print(\"\\nTRAIN MODEL...\")\n",
    "history = model.fit(train_data_multi,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data=val_data_multi,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stopping])\n",
    "model.save('multi-output-timesteps.h5')\n",
    "print(\"\\nModel Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_history(history, 'Multi-Step, Multi-Output Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(10):\n",
    "    multi_step_output_plot(np.squeeze(x[0]), np.squeeze(y[0]), np.squeeze(model.predict(x[0][np.newaxis,:,:,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
